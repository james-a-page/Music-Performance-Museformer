name: asap
generic:
  seed: 1410
  log_dir: './log/'
  clear_log: True
data:
  pretrain_dataset_path: "data/giantMidi/dataset"
  pretrain_metadata_path: "data/giantMidi/dataset/metadata.csv"
  pretrain_new_tokens_dir: "data/giantMidi/vocab"
  pretrain_dataset_save_path: "data/giantMidi/dataset/dataset.csv"
  dataset_path: "data/asap/dataset"
  metadata_path: "data/asap/dataset/metadata.csv"
  new_tokens_dir: "data/asap/vocab"
  dataset_save_path: "data/asap/dataset/dataset.csv"
  max_example_len: 8500
  shuffle: True
  dataset_split: [.8, .1, .1]
  batch_size: 1
training:
  pretrain: False
  epochs: 500000
  save: True
  save_every: 4
  save_dir: "./saved_models/"
  load: True
  decode: True
  decode_every: 4
  decode_dir: "./decoded/"
eval:
  load_path: "./saved_models/model_epoch_72.pt"

transformer:  # [1027, 130, 3, 131, 131, 36, 257, 52]
  embedding_sizes: [1028, 132, 5, 132, 132, 37, 258, 53]  # TODO remove instrument, since all piano
  d_model: 512
  n_head: 8
  max_len: 8500
  ffn_hidden: 2048  # 2048
  drop_prob: 0.45
  n_layers: 6 # 6
  lr: 2e-5
  bayes_compression: True